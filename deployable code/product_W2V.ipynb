{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from scipy import stats\n",
    "import gensim\n",
    "from sklearn.decomposition import PCA\n",
    "def get_prod_W2V(df_products,df_prior_final,df_train_final,data):\n",
    "    '''\n",
    "        Calculates each products vector representaion using Word 2 vector and projects the data into\n",
    "        40 dim using PCA\n",
    "        Args: \n",
    "            df_prior_final :  Users prior order history with products info\n",
    "            df_train_final : Users current order with products info\n",
    "            df_products : products info\n",
    "            data : featurized DF excluing Product2 vec features\n",
    "        Returns:\n",
    "                Featurized DF\n",
    "    '''\n",
    "    products = df_products.set_index('product_id')\n",
    "    df_prior_final['product_id'] = df_prior_final['product_id'].astype(str)\n",
    "    df_train_final['product_id'] = df_train_final['product_id'].astype(str)\n",
    "    train_products = df_train_final.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n",
    "    prior_products = df_prior_final.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n",
    "    sentences = prior_products.append(train_products)\n",
    "    longest = np.max(sentences.apply(len))\n",
    "    # preparing data in list of list format that Gensim expects\n",
    "    sentences = sentences.values\n",
    "    #print(longest)\n",
    "    # We have used window=longest since if we use smaller window then products that are outside the window\n",
    "    # will not be considered in same context though they are added to cart agaist same order. That's why\n",
    "    # we are setting windsize large enough to accomodate all products agaist same order\n",
    "    model = gensim.models.Word2Vec(sentences, size=100, window=longest, min_count=2, workers=4)\n",
    "    vocab = list(model.wv.vocab.keys())\n",
    "    pca = PCA(40)\n",
    "    pca.fit(model.wv[vocab])\n",
    "    #print(pca.explained_variance_ratio_)\n",
    "    product2vec = pca.transform(model.wv[vocab])\n",
    "    product2vec = pd.DataFrame(product2vec)\n",
    "    product2vec.columns = [\"pca_\" + str(s) for s in product2vec.columns.tolist()]\n",
    "    product2vec[\"product_id\"] = vocab\n",
    "    product2vec[\"product_id\"] = product2vec[\"product_id\"].astype(int)\n",
    "    # product2vec.to_pickle(\"product2vec.pkl\")\n",
    "    #product2vec = pd.read_pickle(\"product2vec.pkl\")\n",
    "    #Merging with our data DF\n",
    "    data = data.merge(product2vec,on='product_id',how='left')\n",
    "    del product2vec\n",
    "    gc.collect()\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
